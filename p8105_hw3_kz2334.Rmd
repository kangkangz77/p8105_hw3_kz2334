---
title: "p8105_hw3_kz2334"
author: "Kangkang Zhang"
date: "10/8/2018"
output: github_document
---

##Problem 1 


Load required packages.
```{r 1.1}
library(tidyverse)
devtools::install_github("p8105/p8105.datasets")
library(p8105.datasets)
```

---

Load the BRFSS data and do some data cleaning.
```{r 1.2}
data(brfss_smart2010)
brfss_data = brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  filter(topic == "Overall Health", response %in% c("Excellent", "Very good", 
                                                  "Good", "Fair", "Poor")) %>% 
  mutate(response = factor(response, ordered = TRUE, levels = 
                          c("Poor", "Fair", "Good", "Very good", "Excellent")))
```

---

Find out which states were observed at 7 locations in 2002.
```{r 1.3}
brfss_data %>% 
  distinct(locationdesc, locationabbr, year) %>% 
  count(locationabbr, year) %>% 
  filter(year == 2002, n == 7)
```

CT, FL NC were observed at 7 locations in 2002. It shows that the program had great attention to those three states in 2002.

---
Make a “spaghetti plot” that shows the number of locations in each state from 2002 to 2010.
```{r 1.4}
brfss_data %>% 
  group_by(locationabbr, year) %>% 
  summarise(n = n_distinct(locationdesc)) %>% 
ggplot(aes(y = n, x = year, color = locationabbr)) + 
  geom_line() + 
  labs(
    title = "spaghetti plot",
    x = "Year",
    y = "Number of Locations"
  ) +
  theme_bw() + 
  viridis::scale_color_viridis(
    name = "State", 
    discrete = TRUE
  ) 
  
```

We can see that the numbers of locations in majority of states fluctuated within [0, 10] from 2002 to 2010. There was a state with number less than 10 in 2006, then rapidly grow up to larger than 40 in 2007. 

---

Make a table showing, for the years 2002, 2006, and 2010, the mean and standard deviation of the proportion of “Excellent” responses across locations in NY State.
```{r 1.5}
brfss_data %>%
  filter(year %in% c(2002, 2006, 2010), locationabbr == "NY") %>% 
  group_by(year, response) %>% 
  summarise(mean = mean(data_value),
            standard_deviation = sd(data_value)) %>% 
  filter(response == "Excellent") %>% 
knitr::kable(digits = 2)
```

The mean of proportion of "Excellent" Response in locations in NY varied a little among those years. The standard deviation of "Excellent" Response in locations in NY were almost the same among those years.

---

Make a five-panel plot that shows the average proportion in each response category for each year and each state.
```{r 1.6}
brfss_data %>% 
  group_by(year, locationabbr, response) %>% 
  summarise(mean_proportion = mean(data_value, na.rm =TRUE)) %>% 
ggplot(aes(y = mean_proportion, x = year, color = locationabbr)) + 
  geom_line(show.legend=F) + 
  labs(
    title = "panel plot category by response",
    x = "Year",
    y = "Proportion of Response"
  ) +
  facet_grid( ~ response) + 
  theme_bw() + 
  viridis::scale_color_viridis(
    name = "State", 
    discrete = TRUE)
```

We can see from the plot that globally, "Very Good" has the largest proportion among those response. The distribution of proportion of "Good" is very close to the distribution of "Very Good". The proportion of "Excellent" has median value among them. The proportion of "Poor" is the least among them.

##Problem 2

Load the instacart data and do some data cleaning.
```{r 2.1}
data(instacart)
instacart_data = instacart %>% 
  janitor::clean_names() 

instacart_data
```

Instacart dataset tells imformation about transactions of online grocery shopping. 

*   The size of the dataset is (`r dim(instacart_data)`). 
*   It contains integer and chracter variables. 
*   There are `r count(distinct(instacart_data, order_id))` unique orders.
*   `r round(mean(instacart_data$reordered)*100, 2)`% of products were not bought for the first time.
*   The maximum times of orders for one person is `r max(instacart_data$order_number)`.

---

Find out how many aisles are there, and which aisles are the most items ordered from.
```{r 2.2}
instacart_data %>% 
  group_by(aisle_id, aisle) %>% 
  summarise( n = n_distinct(product_id)) %>% 
  arrange(desc(n))
```
There are 134 aisles, and most items ordered, whose number is 943, are from  candy chocolate.

---

Make a plot that shows the number of items ordered in each aisle. Order aisles sensibly, and organize your plot so others can read it.
```{r 2.3}
instacart_data %>% 
  distinct(product_id, aisle_id, aisle) %>% 
  ggplot(aes(x = aisle_id)) +
  geom_histogram( bins = 134, fill = "black", color = "white") +
  scale_x_continuous(breaks = seq(0, 134, 5)) +
  labs(
    title = "Number of items ordered in each aisle",
    x = "Aisle ID",
    y = "Number of items"
  ) +
  theme_bw()
```


